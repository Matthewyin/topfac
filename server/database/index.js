// JSON æ•°æ®è®¿é—®å±‚
// æä¾›ç±»ä¼¼ ORM çš„æ•°æ®æ“ä½œæ¥å£

import fs from 'fs-extra'
import path from 'path'
import { fileURLToPath } from 'url'
import { promisify } from 'util'
import { randomBytes } from 'crypto'

const __filename = fileURLToPath(import.meta.url)
const __dirname = path.dirname(__filename)

// æ•°æ®ç›®å½•è·¯å¾„
const DATA_DIR = path.join(__dirname, '../../data')

// æ•°æ®æ–‡ä»¶é…ç½®
const DATA_FILES = {
  projects: 'projects.json',
  project_versions: 'project_versions.json',
  parsed_data: 'parsed_data.json',
  ai_configs: 'ai_configs.json',
  component_templates: 'component_templates.json'
}

/**
 * JSON æ•°æ®åº“ç±»
 */
class JSONDatabase {
  constructor() {
    this.cache = new Map() // æ•°æ®ç¼“å­˜
    this.locks = new Map() // æ–‡ä»¶é”æ˜ å°„
    this.cacheTimeout = 60000 // ç¼“å­˜è¶…æ—¶æ—¶é—´ï¼ˆ60ç§’ï¼‰
    this.cacheTimestamps = new Map() // ç¼“å­˜æ—¶é—´æˆ³
    this.initializeDataFiles()
  }

  /**
   * åˆå§‹åŒ–æ•°æ®æ–‡ä»¶
   */
  async initializeDataFiles() {
    // ç¡®ä¿æ•°æ®ç›®å½•å­˜åœ¨
    await fs.ensureDir(DATA_DIR)
    await fs.ensureDir(path.join(DATA_DIR, 'backups'))

    // åˆå§‹åŒ–æ•°æ®æ–‡ä»¶
    for (const [table, filename] of Object.entries(DATA_FILES)) {
      const filePath = path.join(DATA_DIR, filename)
      
      if (!await fs.pathExists(filePath)) {
        const initialData = {
          data: [],
          metadata: {
            created_at: new Date().toISOString(),
            last_updated: new Date().toISOString(),
            total_count: 0
          }
        }
        await fs.writeJson(filePath, initialData, { spaces: 2 })
        console.log(`ğŸ“„ åˆå§‹åŒ–æ•°æ®æ–‡ä»¶: ${filename}`)
      }
    }
  }

  /**
   * æ£€æŸ¥ç¼“å­˜æ˜¯å¦æœ‰æ•ˆ
   */
  isCacheValid(table) {
    if (!this.cache.has(table)) return false

    const timestamp = this.cacheTimestamps.get(table)
    if (!timestamp) return false

    return (Date.now() - timestamp) < this.cacheTimeout
  }

  /**
   * è¯»å–æ•°æ®æ–‡ä»¶ï¼ˆå¸¦ç¼“å­˜ï¼‰
   */
  async readData(table, useCache = true) {
    const filename = DATA_FILES[table]
    if (!filename) {
      throw new Error(`æœªçŸ¥çš„æ•°æ®è¡¨: ${table}`)
    }

    // æ£€æŸ¥ç¼“å­˜
    if (useCache && this.isCacheValid(table)) {
      return this.cache.get(table)
    }

    const filePath = path.join(DATA_DIR, filename)

    try {
      const data = await fs.readJson(filePath)

      // æ›´æ–°ç¼“å­˜
      this.cache.set(table, data)
      this.cacheTimestamps.set(table, Date.now())

      return data
    } catch (error) {
      console.error(`è¯»å–æ•°æ®æ–‡ä»¶å¤±è´¥: ${filename}`, error)
      const defaultData = {
        data: [],
        metadata: {
          created_at: new Date().toISOString(),
          last_updated: new Date().toISOString(),
          total_count: 0
        }
      }

      // ç¼“å­˜é»˜è®¤æ•°æ®
      this.cache.set(table, defaultData)
      this.cacheTimestamps.set(table, Date.now())

      return defaultData
    }
  }

  /**
   * æ¸…é™¤ç¼“å­˜
   */
  clearCache(table = null) {
    if (table) {
      this.cache.delete(table)
      this.cacheTimestamps.delete(table)
    } else {
      this.cache.clear()
      this.cacheTimestamps.clear()
    }
  }

  /**
   * è·å–æ–‡ä»¶é”
   */
  async acquireLock(table) {
    const lockKey = `lock_${table}`

    // å¦‚æœå·²ç»æœ‰é”ï¼Œç­‰å¾…é‡Šæ”¾
    while (this.locks.has(lockKey)) {
      await new Promise(resolve => setTimeout(resolve, 10))
    }

    // è®¾ç½®é”
    this.locks.set(lockKey, Date.now())
  }

  /**
   * é‡Šæ”¾æ–‡ä»¶é”
   */
  releaseLock(table) {
    const lockKey = `lock_${table}`
    this.locks.delete(lockKey)
  }

  /**
   * åŸå­å†™å…¥æ•°æ®æ–‡ä»¶
   */
  async writeData(table, data) {
    const filename = DATA_FILES[table]
    if (!filename) {
      throw new Error(`æœªçŸ¥çš„æ•°æ®è¡¨: ${table}`)
    }

    const filePath = path.join(DATA_DIR, filename)
    const tempPath = `${filePath}.tmp.${randomBytes(8).toString('hex')}`

    // æ›´æ–°å…ƒæ•°æ®
    data.metadata = {
      ...data.metadata,
      last_updated: new Date().toISOString(),
      total_count: data.data.length
    }

    try {
      // è·å–æ–‡ä»¶é”
      await this.acquireLock(table)

      // å…ˆå†™å…¥ä¸´æ—¶æ–‡ä»¶
      await fs.writeJson(tempPath, data, { spaces: 2 })

      // åŸå­æ€§ç§»åŠ¨åˆ°ç›®æ ‡æ–‡ä»¶
      await fs.move(tempPath, filePath, { overwrite: true })

      // æ¸…é™¤ç¼“å­˜
      this.clearCache(table)

      console.log(`ğŸ’¾ æ•°æ®å·²ä¿å­˜: ${filename} (${data.data.length} æ¡è®°å½•)`)
    } catch (error) {
      // æ¸…ç†ä¸´æ—¶æ–‡ä»¶
      try {
        await fs.remove(tempPath)
      } catch (cleanupError) {
        console.warn(`æ¸…ç†ä¸´æ—¶æ–‡ä»¶å¤±è´¥: ${tempPath}`, cleanupError)
      }

      console.error(`å†™å…¥æ•°æ®æ–‡ä»¶å¤±è´¥: ${filename}`, error)
      throw error
    } finally {
      // é‡Šæ”¾æ–‡ä»¶é”
      this.releaseLock(table)
    }
  }

  /**
   * æŸ¥æ‰¾æ‰€æœ‰è®°å½•
   */
  async findAll(table, filter = {}) {
    const fileData = await this.readData(table)
    let records = fileData.data

    // ç®€å•è¿‡æ»¤
    if (Object.keys(filter).length > 0) {
      records = records.filter(record => {
        return Object.entries(filter).every(([key, value]) => {
          return record[key] === value
        })
      })
    }

    return records
  }

  /**
   * æŒ‰ ID æŸ¥æ‰¾è®°å½•
   */
  async findById(table, id) {
    const records = await this.findAll(table)
    return records.find(record => record.id === id) || null
  }

  /**
   * åˆ›å»ºè®°å½•
   */
  async create(table, record) {
    const fileData = await this.readData(table)
    
    // ç”Ÿæˆ ID (å¦‚æœæ²¡æœ‰)
    if (!record.id) {
      record.id = this.generateId()
    }

    // æ·»åŠ æ—¶é—´æˆ³
    record.created_at = new Date().toISOString()
    record.updated_at = new Date().toISOString()

    fileData.data.push(record)
    await this.writeData(table, fileData)

    return record
  }

  /**
   * æ›´æ–°è®°å½•
   */
  async update(table, id, updates) {
    const fileData = await this.readData(table)
    const index = fileData.data.findIndex(record => record.id === id)

    if (index === -1) {
      throw new Error(`è®°å½•ä¸å­˜åœ¨: ${id}`)
    }

    // æ›´æ–°è®°å½•
    fileData.data[index] = {
      ...fileData.data[index],
      ...updates,
      updated_at: new Date().toISOString()
    }

    await this.writeData(table, fileData)
    return fileData.data[index]
  }

  /**
   * åˆ é™¤è®°å½•
   */
  async delete(table, id) {
    const fileData = await this.readData(table)
    const index = fileData.data.findIndex(record => record.id === id)

    if (index === -1) {
      throw new Error(`è®°å½•ä¸å­˜åœ¨: ${id}`)
    }

    const deletedRecord = fileData.data.splice(index, 1)[0]
    await this.writeData(table, fileData)

    return deletedRecord
  }

  /**
   * åˆ›å»ºæ•°æ®å¤‡ä»½
   */
  async createBackup(table = null) {
    const timestamp = new Date().toISOString().replace(/[:.]/g, '-')
    const backupDir = path.join(DATA_DIR, 'backups', timestamp)

    await fs.ensureDir(backupDir)

    const tablesToBackup = table ? [table] : Object.keys(DATA_FILES)

    for (const tableName of tablesToBackup) {
      const filename = DATA_FILES[tableName]
      const sourcePath = path.join(DATA_DIR, filename)
      const backupPath = path.join(backupDir, filename)

      if (await fs.pathExists(sourcePath)) {
        await fs.copy(sourcePath, backupPath)
      }
    }

    console.log(`ğŸ“¦ æ•°æ®å¤‡ä»½å·²åˆ›å»º: ${backupDir}`)
    return backupDir
  }

  /**
   * æ¢å¤æ•°æ®å¤‡ä»½
   */
  async restoreBackup(backupPath) {
    if (!await fs.pathExists(backupPath)) {
      throw new Error(`å¤‡ä»½ç›®å½•ä¸å­˜åœ¨: ${backupPath}`)
    }

    // å…ˆåˆ›å»ºå½“å‰æ•°æ®çš„å¤‡ä»½
    await this.createBackup()

    // æ¢å¤å¤‡ä»½æ•°æ®
    for (const [tableName, filename] of Object.entries(DATA_FILES)) {
      const backupFilePath = path.join(backupPath, filename)
      const targetPath = path.join(DATA_DIR, filename)

      if (await fs.pathExists(backupFilePath)) {
        await fs.copy(backupFilePath, targetPath, { overwrite: true })
      }
    }

    // æ¸…ç†ç¼“å­˜
    this.cache.clear()

    console.log(`ğŸ”„ æ•°æ®å·²ä»å¤‡ä»½æ¢å¤: ${backupPath}`)
  }

  /**
   * æ¸…ç†æ—§å¤‡ä»½
   */
  async cleanupOldBackups(keepDays = 7) {
    const backupDir = path.join(DATA_DIR, 'backups')
    const cutoffTime = Date.now() - (keepDays * 24 * 60 * 60 * 1000)

    try {
      const backupFolders = await fs.readdir(backupDir)

      for (const folder of backupFolders) {
        const folderPath = path.join(backupDir, folder)
        const stats = await fs.stat(folderPath)

        if (stats.isDirectory() && stats.mtime.getTime() < cutoffTime) {
          await fs.remove(folderPath)
          console.log(`ğŸ—‘ï¸ å·²åˆ é™¤æ—§å¤‡ä»½: ${folder}`)
        }
      }
    } catch (error) {
      console.warn('æ¸…ç†æ—§å¤‡ä»½æ—¶å‡ºé”™:', error)
    }
  }

  /**
   * ç”Ÿæˆå”¯ä¸€ ID
   */
  generateId() {
    return `${Date.now()}_${Math.random().toString(36).substr(2, 9)}`
  }
}

// å¯¼å‡ºå•ä¾‹å®ä¾‹
export const db = new JSONDatabase()
export default db
